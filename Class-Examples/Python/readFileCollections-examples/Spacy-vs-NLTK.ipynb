{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c38a5c62-1925-4c1e-b36b-16cd8d2fcf27",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging is Weird\n",
    "\n",
    "NLTK shows us some weird part of speech tagging. We might decide that it's just a bit unreliable here. In this notebook, we're going to compare the part of speech tagging from NLTK with a newer library called spaCy that's used widely in industry for natural language processing (NLP). We'll also practice preparing some simple files for output. \n",
    "\n",
    "### Installs\n",
    "To try out spaCy, you need to **open your terminal and install it first**:\n",
    "`pip install spacy` \n",
    "\n",
    "### Language Models\n",
    "Like NLTK's collections that we downloaded, [spaCy has trained language models](https://spacy.io/usage/models) to download. You download these in your Python script after you import spacy, and after you download once, you don't need to do it again (so you can comment out the download line). We're going to try the medium and large models in English. (It's good to know that both spaCy and NLTK have resources for NLP on other languages, too!)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863583d-944b-4cdb-8329-8f89cbb9c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b96b7-90fa-49cb-bd8f-31c79e327de5",
   "metadata": {},
   "source": [
    "### Downloading language models\n",
    "To work with spaCy's pre-trained language models, you need to download them to you virtual environment. There are:\n",
    "* en_core_web_sm (smallest--not as much info as the others)\n",
    "* **en_core_web_md** (Pretty good date here, size: 34 MB )\n",
    "* **en_core_web_lg** (Lots of data here, size: 400 MB.)\n",
    "Note that the LARGEST  one will have the most data and probably be the most reliable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f65be-d71c-4e01-85ae-12f5aa8918be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAN YOU SKIP THIS???\n",
    "# After you download a model into your virtual environment for the first time, you can comment out the download line.\n",
    "# spaCy's medium and large models will give us the best results for NLP tagging.\n",
    "# nlp = spacy.cli.download(\"en_core_web_sm\")\n",
    "# nlp = spacy.cli.download(\"en_core_web_md\")\n",
    "nlp = spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e169c-e7d3-43db-a4ce-e60d9397d1cd",
   "metadata": {},
   "source": [
    "### Load the model \n",
    "Now we redefine the nlp variable to LOAD the model you downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b994b-63fa-4143-b460-186f8b123aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd15c8-4a46-44fd-9b05-6019b86d7549",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'hughes-txt/sixteen.txt'\n",
    "f = open(filepath, 'r', encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43e08af-56b1-45c4-8d80-1b78f7c7290f",
   "metadata": {},
   "source": [
    "## spaCy Part of Speech Tagging\n",
    "spaCy needs to read the str() of our text to generate a dictionary of information on each word.\n",
    "So we go back to our opened file! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753679b-61df-4c00-9bcd-e7ac17273358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used nlp as our variable for the spaCy operations. \n",
    "# f is our variable for the source file. spaCy doesn't tell you how it tokenizes or what it's doing (sigh). \n",
    "spacyRead = nlp(f)\n",
    "for token in spacyRead:\n",
    "    print(token.text, \"---->\", token.pos_, \":::::\", token.lemma_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cfb906-3ef6-454c-8318-5467bc51aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"DET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a523193-8091-43da-9eaf-c94c1bd527dc",
   "metadata": {},
   "source": [
    "### For spaCy: define a function to collect the words you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d43a3-3597-4ab3-ab0a-b619468dbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCollector(words):\n",
    "    wordList = []\n",
    "    count = 0\n",
    "    for token in words:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            count += 1\n",
    "            # print(count, \": \", token.text, \" lemma: \", token.lemma_, \" pos: \", token.pos_)\n",
    "            # don't forget the underscore after token.lemma_ , token.pos_, etc.!\n",
    "            wordList.append(token.lemma_)\n",
    "            # print(count, \": \", token, token.pos_)\n",
    "    # print(count, \": \", adjectives)\n",
    "    return wordList\n",
    "myWords = wordCollector(spacyRead)\n",
    "print(myWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c819d4-9ad7-4188-aaeb-5bb8315874f9",
   "metadata": {},
   "source": [
    "### Frequency of words\n",
    "Here is something we can do: Because we didn't make a set of unique words, we have a list full of the original words. \n",
    "The Counter function in collections offers a speedy way to count the number of times something appears in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991948d9-8a36-473d-89f5-69fe77e792dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_freq = Counter(myWords)\n",
    "# most_common() converts the Counter's dictionary to a tuple series and sorts it\n",
    "ranked = word_freq.most_common()\n",
    "topTen = word_freq.most_common(10)\n",
    "print(topTen)\n",
    "lastTen = word_freq.most_common()[:-11:-1]\n",
    "print(lastTen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de28c039-9a52-4d5a-89c0-1ca5fd7c91b4",
   "metadata": {},
   "source": [
    "## Write something to an output file (just text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7a42f-14e2-4a73-9d5b-70e04f5d9adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"verbFreq.txt\", \"w\") as o:\n",
    "    for r in ranked:\n",
    "        o.write(str(r) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163a80b-7d37-48f3-8683-f0e551186705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
