{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c621e7650d4943",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Exploring NLP on project XML files \n",
    "You can write this in a new Python file in Pycharm, or you can work on it as a Jupyter Lab notebook that you can edit on your local computer just using a web browser. I recommend working on this in as a Jupyter Lab notebook. \n",
    "\n",
    "I recommend that you copy my notebook file into your own filespace (a personal GitHub repo) where you set up a virtual environment.\n",
    "\n",
    "* Navigate to your filespace (preferably a personal GitHub repo) in your Git Bash (Windows) or Terminal (Mac), and set up your virtual environment with this command:\n",
    "\n",
    "`python -m venv .`\n",
    "\n",
    "Troubleshooting: If your system does not respond to `python`, run `python3 -m venv .` instead. \n",
    "\n",
    "    * In Windows that will create a `Scripts/` directory in your fastbook repo.\n",
    "    * In Mac, it will create a `bin/` directory.\n",
    "    * Look inside either of these: you'll see pip and other executables to manage your local venv. See the activate script? We need to run it.\n",
    "* Run the appropriate activate script for your system. There's a script file named \"activate\" in your new virtual environmen, and you basically need to run this command: source yourFilePath/To/activate Enter the command appropriate to your system. If you are at the root of your GitHub repo with the virtual environment folders nested inside, you should run one of the following commands appropriate to your computer:\n",
    "    * Windows: `source Scripts/activate`\n",
    "    * Mac: `source bin/activate`\n",
    "* Now try entering: `jupyter lab`.\n",
    "    * If it works, you'll open your directory in a browser and be able to navigate to the interactive notebook, and work with it and edit it there.\n",
    "    * If it doesn't work, you need to install jupyter in your virtual environment: Do that with `pip install jupyterlab`\n",
    "And try again.\n",
    "* Where you've set up your python environment, run `pip install saxonche` or `pip3 install saxonche` as needed.\n",
    "\n",
    "You should be able to run this notebook on your local computer: \n",
    "* Navigate to the Class Examples/Python directory in your Git Bash (Windows) or Terminal (Mac),\n",
    "* Type in `jupyter lab` and press enter\n",
    "* Then open the localhost address you're given in your web browser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install saxonche\n",
    "import os\n",
    "import spacy\n",
    "import re as regex\n",
    "# re lets us work with regular expressions in Python\n",
    "from saxonche import PySaxonProcessor\n",
    "# You may need to pip install saxonche at the command line if the install doesn't work in the notebook here.\n",
    "# This lets us use Saxon XPath parsers over XML files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204f234-ebbb-4867-9cb2-d3494379b392",
   "metadata": {},
   "source": [
    "Remember the spaCy language models? Let's try loading loading the large one to get the maximum amount of information from it! \n",
    "There's a lot we can experiment with from spaCy, so here's a link to the documentation for our ready reference:\n",
    "<https://spacy.io/usage/spacy-101> \n",
    "\n",
    "We're going to start by just reviewing its POS (part of speech) and NER (named entity recognition) taggers to see what we can see in your project files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c9b20-f094-4cc2-9c51-c9ce642a81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.cli.download(\"en_core_web_lg\")\n",
    "# ONLY NEED ABOVE LINE ONCE. REMEMBER: COMMENT OUT THE ABOVE LINE THE NEXT TIME YOU RUN THIS.\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3aa2a5-fef7-40d0-921a-668b9021f09c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Okay, let's explore some project files!\n",
    "We've loaded the XML directory prepared by the Futurama team for our example here. \n",
    "\n",
    "* If you have some basic XML right now, like the Futurama team has prepared, we can easily scope in tagged sections of your collection. Swap out the Futurama collection with yours, and adjust the Python code below accordingly.\n",
    "* If you don't have XML at this point, you can work around this over text files, or just explore the Futurama collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ed67e-3a24-49d0-8a92-526e941ccebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE SOME FILE PATHS FOR INPUT, AND (ONCE WE'RE READY) OUTPUT\n",
    "InputPath = 'futurama-xml'\n",
    "OutputPath = 'testOutput' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5842d99e-4b58-4681-aa39-2ff13aaabde0",
   "metadata": {},
   "source": [
    "Now, here are some functions to: \n",
    "* read input files\n",
    "* pull from the XML elements with some simple XPath\n",
    "* run stuff through spaCy's NLP\n",
    "\n",
    "Read (and adapt) the functions in the following cell from the bottom up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59a76b-0af9-42ce-bfca-c15652b69af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTextFiles(InputPath):\n",
    "    # This function uses XPath to read the XML input\n",
    "    for file in os.listdir(InputPath):\n",
    "        if file.endswith('.xml'):\n",
    "            filepath = f\"{InputPath}/{file}\"\n",
    "            with PySaxonProcessor(license=False) as proc:\n",
    "                xml = open(filepath, encoding='utf-8').read()\n",
    "                # ebb: Here we apply the Saxon processor to read files with XPath.\n",
    "                xp = proc.new_xpath_processor()\n",
    "                node = proc.parse_xml(xml_text=xml)\n",
    "                xp.set_context(xdm_item=node)\n",
    "\n",
    "                # From here on, we select the string that Python will send to NLP. \n",
    "                # xpath = xp.evaluate('//your/xpath/here')\n",
    "                xpath = xp.evaluate('(//speak[@who=\"LEELA\"]/text()) => string-join()')\n",
    "                # print(xpath)\n",
    "                string = str(xpath)\n",
    "                print(string)\n",
    "             \n",
    "readTextFiles(InputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e810d2-bb5a-4698-abaf-88eb68c2c696",
   "metadata": {},
   "source": [
    "def readTextFiles(InputPath):\n",
    "    # This time, let's try XQuery over a collection of files:\n",
    "    with PySaxonProcessor(license=False) as proc:\n",
    "        print(proc.version)\n",
    "        xq = proc.new_xquery_processor()\n",
    "        xq.set_query_base_uri('file://'+getcwd()+'/')\n",
    "        xq.set_query_content('''\n",
    "let $futurama := collection('futurama-xml/?select=*.xml')\n",
    "let $speakers := $futurama//speak/@who => distinct-values() => sort()\n",
    "for $sp in $speakers\n",
    "let $count := $futurama//speak[@who = $sp] => count()\n",
    "order by $count descending\n",
    "return ($sp || ':  ' || $count)\n",
    "    \n",
    "''')\n",
    "        r = xq.run_query_to_value()\n",
    "        print(r)  \n",
    "                               \n",
    "readTextFiles(InputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc1432-9c59-4abc-90ac-8ea1056bf688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22911fbc-58d1-4e33-bea9-a546ebf84d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
