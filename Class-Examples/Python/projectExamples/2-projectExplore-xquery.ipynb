{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c621e7650d4943",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# XQuery in Python: Process a whole collection at once on project XML files \n",
    "\n",
    "Source: <https://stackoverflow.com/questions/75142854/how-to-use-the-collection-function-with-saxonche> \n",
    "\n",
    "## New pip installs\n",
    "* For this homework, you'll need to install the **pathlib** library so we can run XQuery across platforms on Mac *and* Windows. \n",
    "In your python environment for this series of notebooks, run `pip install pathlib`\n",
    "* If you didn't install spacy before, be sure to `pip install spacy`\n",
    "* Also, if you didn't download the spacy large language model, uncomment the line to download the spacy large model to your virtual environment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/thinc/compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "/usr/local/lib/python3.11/site-packages/thinc/compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# !pip install saxonche\n",
    "# !pip install pathlib\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import re as regex\n",
    "# re lets us work with regular expressions in Python\n",
    "from saxonche import PySaxonProcessor\n",
    "from os import getcwd\n",
    "# this lets us retrieve the current working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204f234-ebbb-4867-9cb2-d3494379b392",
   "metadata": {},
   "source": [
    "Remember the spaCy language models? Let's try loading loading the large one to get the maximum amount of information from it! \n",
    "There's a lot we can experiment with from spaCy, so here's a link to the documentation for our ready reference:\n",
    "<https://spacy.io/usage/spacy-101> \n",
    "\n",
    "We're going to start by just reviewing its POS (part of speech) and NER (named entity recognition) taggers to see what we can see in your project files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337c9b20-f094-4cc2-9c51-c9ce642a81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.cli.download(\"en_core_web_lg\")\n",
    "# ONLY NEED ABOVE LINE ONCE. REMEMBER: COMMENT OUT THE ABOVE LINE THE NEXT TIME YOU RUN THIS.\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3aa2a5-fef7-40d0-921a-668b9021f09c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Okay, let's explore some project files!\n",
    "We've loaded the XML directory prepared by the Futurama team for our example here. \n",
    "\n",
    "* If you have some basic XML right now, like the Futurama team has prepared, we can easily scope in tagged sections of your collection. Swap out the Futurama collection with yours, and adjust the Python code below accordingly.\n",
    "* If you don't have XML at this point, you can work around this over text files, or just explore the Futurama collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e5ed67e-3a24-49d0-8a92-526e941ccebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE SOME FILE PATHS FOR INPUT, AND (ONCE WE'RE READY) OUTPUT\n",
    "InputPath = 'futurama-xml'\n",
    "OutputPath = 'testOutput' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5842d99e-4b58-4681-aa39-2ff13aaabde0",
   "metadata": {},
   "source": [
    "The next cell demonstrates the xpath() function, set up to run over individual files.\n",
    "Let's look at how it returns information about distinct values of speakers. We're exploring distinct-values() and count() functions here. Try removing them and putting them back to see what the effect of distinct-values() is on the count. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84065536-1328-4c31-887b-57ea4576301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTextFiles(InputPath):\n",
    "    # This function uses XPath to read the XML input\n",
    "    for file in os.listdir(InputPath):\n",
    "        if file.endswith('.xml'):\n",
    "            filepath = f\"{InputPath}/{file}\"\n",
    "            with PySaxonProcessor(license=False) as proc:\n",
    "                xml = open(filepath, encoding='utf-8').read()\n",
    "                # ebb: Here we apply the Saxon processor to read files with XPath.\n",
    "                xp = proc.new_xpath_processor()\n",
    "                node = proc.parse_xml(xml_text=xml)\n",
    "                xp.set_context(xdm_item=node)\n",
    "\n",
    "                # From here on, we select the string that Python will send to NLP. \n",
    "                # xpath = xp.evaluate('//your/xpath/here')\n",
    "                xpath = xp.evaluate('//speak/@who => distinct-values() => sort()')\n",
    "                count = xp.evaluate('//speak/@who => distinct-values() => count()')\n",
    "                string = str(xpath)\n",
    "                print(xpath)\n",
    "                # xpath is going to go file by file.\n",
    "             \n",
    "readTextFiles(InputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4454e36-c2af-4d35-ad60-964a78567779",
   "metadata": {},
   "source": [
    "## Introducing XQuery! \n",
    "XQuery is what we want to use to help read data from across a whole directory, or \"corpus\" collection of files. \n",
    "XQuery can be written as a separate file (with .xql or .xquery extension) in oXygen over a directory. But we will find it more useful \n",
    "to apply it in Python if we're working on natural language processing applications. \n",
    "\n",
    "### Setting up XQuery in Python \n",
    "We use the same \"boilerplate\" PySaxonProcessor lines, but switch from xpath to the xquery processor.\n",
    "\n",
    "\n",
    "Requirements: \n",
    "* We need all the xq lines to plug this processing into Python. You can use this code as a starter for your projects.\n",
    "* The XQuery script is written inside a quoted block in the set_query_content() function that needs to take a quoted string, just like in the cell below.\n",
    "* We need the run_query_to_value() function to execuit the script we're writing.\n",
    "  \n",
    "\n",
    "**Reading the collection**: We're setting this up to read a `collection()` function, which is a directory of XML files. \n",
    "**Writing XQuery**: This involves setting simple variables equal to xpath expressions. XQuery variables are defined with a `$`.\n",
    "**XQuery Comments**: look like sideways smiley faces. `(: I'm an XQuery comment :)`\n",
    "\n",
    "Let's take a look:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f62be-51be-472c-9ce1-6fbe9143d141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def xqueryOverFiles(InputPath):\n",
    "    # This time, let's try XQuery over a collection of files:\n",
    "    with PySaxonProcessor(license=False) as proc:\n",
    "        print(proc.version)\n",
    "        xq = proc.new_xquery_processor()\n",
    "        # This only works on Mac / Linux: xq.set_query_base_uri('file://'+getcwd()+'/')\n",
    "        xq.set_query_base_uri(Path('.').absolute().as_uri() + '/')\n",
    "        xq.set_query_content('''\n",
    "let $futurama := collection('futurama-xml/?select=*.xml')\n",
    "let $speakers := $futurama//speak/@who => distinct-values() => sort()\n",
    "let $count := count($speakers)\n",
    "return $speakers\n",
    "\n",
    "   (: ebb: I'm writing in an XQuery comment, and pointing out you can define and return any variable you want in the XQuery zone. :)\n",
    "   (: ebb: Try changing this one to return $speakers instead of the $count variable. :)\n",
    "   (: ebb: We're writing an query-based syntax called FLWOR (pronounced \"flower\") and every FLWOR requires a return statement at the end. :)\n",
    "    \n",
    "''')\n",
    "        r = xq.run_query_to_value()\n",
    "        print(r)  \n",
    "                               \n",
    "xqueryOverFiles(InputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9a52a-1c66-4f2d-abb4-81408479de29",
   "metadata": {},
   "source": [
    "## What's the difference? \n",
    "\n",
    "Notice that you return just one count for the entire collection, not 72 different counts for the speakers in each file.\n",
    "How can we use this? \n",
    "\n",
    "We can get pull information from across the entire collection and find out literally who has the most speeches in the whole series. \n",
    "Take a look at this code. Don't worry if you don't know how to write it yet. I just want to show you for demonstration purposes! \n",
    "What's here is a nearly full \"FLWOR statement\" which stands for :\n",
    "\n",
    "* For\n",
    "* Let\n",
    "* Where\n",
    "* Order by\n",
    "* Return\n",
    "\n",
    "The only things required in a FLWOR statements are L and R. The others give you extra powers like we're seeing here.\n",
    "\n",
    "**IMPORTANT: You're only allowed one return per FLWOR.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3c8f11-81c1-4e3a-a182-9437e50870b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xqueryOverFiles(InputPath):\n",
    "    # This time, let's try XQuery over a collection of files:\n",
    "    with PySaxonProcessor(license=False) as proc:\n",
    "        print(proc.version)\n",
    "        xq = proc.new_xquery_processor()\n",
    "        xq.set_query_base_uri(Path('.').absolute().as_uri() + '/')\n",
    "        xq.set_query_content('''\n",
    "let $futurama := collection('futurama-xml/?select=*.xml')\n",
    "let $speakers := $futurama//speak/@who => distinct-values() => sort()\n",
    "let $count := count($speakers)\n",
    "for $sp in $speakers\n",
    "    let $count := $futurama//speak[@who = $sp] => count()\n",
    "    where $count > 100\n",
    "    order by $count descending\n",
    "    return ($sp || ':  ' || $count)\n",
    " \n",
    "''')\n",
    "        r = xq.run_query_to_value()\n",
    "        print(r)  \n",
    "                            \n",
    "\n",
    "xqueryOverFiles(InputPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14970c9-f8e6-4cd5-86ed-32765e274c8c",
   "metadata": {},
   "source": [
    "For this notice how we can move **deliberately** in XQuery from information on the whole collection, to information based on individuals in a series.\n",
    "The counts we're seeing are NOT based on files, but on info about each speaker! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b430fc-4404-4a1c-879f-c6909dba3231",
   "metadata": {},
   "source": [
    "## For statements, measurements, order by, return\n",
    "\n",
    "\n",
    "* Let's choose a character from Futurama who gets a LOT of speeches and use XQuery to pull all their speeches from across the entire collection into one return.\n",
    "The next code block is written to show you how to get all the speeches of one character in the WHOLE collection. You can change this to any other character you wish.\n",
    "* Let's go through each speech individually and meaasure it: \n",
    "* Try out defining a new variable in the XQuery, to use the `string-length()` function, so you can measure the text of the speeches. Try it out!\n",
    "\n",
    "* We're going to write a for statement so we can evaluate each speech, and order our results based on how long the speeches are,\n",
    "     * We'll use the XPath `string-length()` function to measure each speech\n",
    "     * We'll work through an XQuery `for` and `order by`\n",
    "     * Let's see if we can return the speeches from shortest to longest, then try adding the word `descending` to order them longest to shortest!\n",
    "\n",
    "\n",
    "* YOUR TURN: Edit the code below to return some alternative information! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18659ee5-2877-412b-b627-059c5c5c6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xqueryAndNLP(InputPath):\n",
    "    # This time, let's try XQuery over a collection of files:\n",
    "    with PySaxonProcessor(license=False) as proc:\n",
    "        print(proc.version)\n",
    "        xq = proc.new_xquery_processor()\n",
    "        xq.set_query_base_uri(Path('.').absolute().as_uri() + '/')\n",
    "        xq.set_query_content('''\n",
    "let $futurama := collection('futurama-xml/?select=*.xml')\n",
    "let $benderSpeeches := $futurama//speak[@who=\"BENDER\"]\n",
    "let $benderTextsOnly := $benderSpeeches/text() \n",
    "for $bt in $benderTextsOnly\n",
    "   let $length := $bt ! string-length()\n",
    "   where $length gt 200\n",
    "   order by $length descending\n",
    "   return $bt\n",
    " \n",
    "''')\n",
    "        r = xq.run_query_to_value()\n",
    "        print(r)  \n",
    "                            \n",
    "\n",
    "xqueryAndNLP(InputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990125f6-ce31-4842-bf8e-6c951412def0",
   "metadata": {},
   "source": [
    "## Experimenting with some functions\n",
    "\n",
    "\n",
    "Remember how we were going to apply some NLP from spaCy? The next part of this exercise is to take the output of this XQuery function and pass it to the spaCY language model!\n",
    "\n",
    "We need XQuery in our function above to return just one string if we want to deliver that to spaCY and NLP tools. The way I left this code, it's returning thousands of strings.\n",
    "\n",
    "* Find out  **how many strings** is the XQuery in the codeblock below is returning? Modify the XQuery to show you this `count()`.\n",
    "* To bundle them all together in one string **add a string-join()** function.\n",
    "\n",
    "\n",
    "* Then we're going to pass them on to other tools.\n",
    "* So here's your challenge: Write some code that returns all the text of one speaker. (Or adjust the code to use in your project.)\n",
    "* Then apply `string-join()` to make the XQuery code return in a single string.\n",
    "* **Write a new function** that delivers this single string to be processed with spaCy in some way.\n",
    "    * You can build your code in a new cell block below this one.\n",
    "    *  You'll probably want to review [this spaCy NLP assignment](https://github.com/newtfire/textAnalysis-Hub/blob/main/python-nlp-exercise1.md#write-some-python-code-to-do-the-following)\n",
    "    * Write your code to return any information of interest from spaCy, following the spaCy documentation as we did in that earlier assignment! Try looking for one or two different kinds of language. What are the most popular verbs, adjectives, nouns? Try out the NER (named entity recognition)...Write your code in your copy of this Jupyter Notebook to complete this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574b646-79c0-459b-8f84-17f053e81108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40dce36-6193-4f3f-ae32-63856bae35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
