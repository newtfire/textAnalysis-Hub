{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48b6588-b167-480c-9fe6-171df14855fe",
   "metadata": {},
   "source": [
    "## Hello DIGIT world!\n",
    "Welcome, DIGIT student Python adventurer! This is the **Jupyter Notebook** version of my [exploring-nltk.py](exploring-nltk.py) file. The cells in the notebook will help me demonstrate particular things in class without having to comment everything else out. Jupyter notebooks are written with a combination of markdown cells (like this) for documentation, and cells with executable scripts. You usually have to run the cells in order, but you can choose which ones to run. I'm splitting up my exploring-nltk.py file into tidy cells because my commenting was getting a bit out of hand inside the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4383999d-5213-4f71-acca-478d58e63b1d",
   "metadata": {},
   "source": [
    "### Installs before imports \n",
    "You only need to make installations ONCE in your Python virtual environment (your venv). After that, you're good to go.\n",
    "\n",
    "To install things, open a shell (or use the terminal in PyCharm CE), and be sure the venv is activated--usually you see (venv) in parentheseses. You can activate your venv like this, after navigating to the directory above your .venv file:\n",
    "* On Mac: **.venv/bin/activate**\n",
    "* On Windows: **.venv/bin/activate.bat**\n",
    "\n",
    "We need to install nltk first: in your shell or the Pycharm terminal with .venv activated, run the following:\n",
    "\n",
    "**pip install nltk**\n",
    "\n",
    "Some of you might need to write:\n",
    "**pip3 install nltk**\n",
    "(If this is you and you're annoyed about it, make an alias for pip in your .bashrc or .zshrc to point to pip3 every time you type pip.)\n",
    "\n",
    "*If you, like me, have multiple versions of python on your machine*, run:\n",
    "\n",
    "**python3.12 -m pip install nltk**\n",
    "\n",
    "#### Other libraries to install:\n",
    "These next ones are for plotting interactive graphs:\n",
    "* **pip install matplotlib**\n",
    "* **pip install tk**\n",
    "\n",
    "#### For making Jupyter notebooks like this:\n",
    "For me to make this Jupyter notebook, I needed to install:\n",
    "* **python3.12 -m pip install notebook**\n",
    "* **python3.12 -m pip install notebook ipykernel**\n",
    "Then I just ran the following to launch the. notebook in a web browser for editing:\n",
    "**python3.12 -m jupyter notebook** or just **jupyter notebook** \n",
    "\n",
    "### After installs, time to start writing the script, with import lines\n",
    "Then we can import these things in your Python script, which is what our first executable code cell is doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477fc06-86c0-4310-b862-1108ec67b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.corpus\n",
    "# The next line downloads all the example texts used in the NLTK book at https://www.nltk.org/book !\n",
    "# You can comment out the download line after the first time you do it.\n",
    "nltk.download('book')\n",
    "from nltk.book import *\n",
    "# The next line lets us do GET requests from remote URLs on the web:\n",
    "from urllib import request\n",
    "# The following import lines are for plotting interactive visualizations in Python\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3e10be-393b-4c5f-b7e7-2a3f8125d36f",
   "metadata": {},
   "source": [
    "### Smoke test for graphing libraries\n",
    "After the imports, run the next cells to see if graphing works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae06c6-aeba-499a-8c27-98051a9fca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116825df-d077-4ad6-ad0c-3658637a9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "### See how these words are dispersed in NLTK text 1 (Moby Dick)\n",
    "words = [\"whale\", \"sea\", \"ship\", \"captain\"]\n",
    "nltk.draw.dispersion_plot(text1, words)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9306fcb-a94c-40d9-8b28-4a2560dd9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another dispersion plot written closer to the NLTK example:\n",
    "# Choose the text first (text 4 is Inaugural Addresses):\n",
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e36638-0119-4d3d-ba20-bf4e66ce5f01",
   "metadata": {},
   "source": [
    "### Take a look at some common contexts for uses of the words\n",
    "\"monstrous\" and \"very\" in text1\n",
    "Try changing these up for different texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db977c6a-a18a-4ed2-9eb0-f25e71fc1b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "text6.common_contexts([\"find\",\"seek\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d9472b-89df-4070-9045-c04af7748ccb",
   "metadata": {},
   "source": [
    "### Look for similar words\n",
    "This looks for words that appear in the same context as the word you enter\n",
    "SO, I used text6 (\"Monty Python and the Holy Grail\") for this next example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f0c62-9a74-41f9-b577-a4f6b81dec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "text6.similar('grail')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7b895-cd86-43c2-8a84-e4c3a356c0e0",
   "metadata": {},
   "source": [
    "### Pulling files from a web url\n",
    "For this, let's pull *Blithedale Romance* direct from Project Gutenberg (just like David did with it while introducing invisible XML).\n",
    "I'm also demonstrating **how to make \"picture string\" variables** so you can easily know what you're printing out in the console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8adfbb-d331-4f9a-a3f3-bb979ebab025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blithedale Romance text file on Project Gutenberg\n",
    "bookurl= \"https://www.gutenberg.org/cache/epub/2081/pg2081.txt\"\n",
    "response = request.urlopen(bookurl)\n",
    "br = response.read().decode('utf8')\n",
    "type(br)\n",
    "print(len(br))\n",
    "# make a variable\n",
    "howLong = len(br)\n",
    "# picture string version! \n",
    "print(f\"howLong = {howLong}\")\n",
    "novelSlice = br[:500]\n",
    "print(f\"novelSlice = {novelSlice}\")\n",
    "\n",
    "# splitEmUp = br.split()\n",
    "# print(f\"splitEmUp = {splitEmUp}\")\n",
    "\n",
    "for token in splitEmUp:\n",
    "    if token.endswith('ing'):\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af8a0f-c093-4035-b60c-11f9e45db9ef",
   "metadata": {},
   "source": [
    "### Make a Text Concordance \n",
    "Use the concordance feature...In the NLTK book, they introduce this with the prefab text of Jane Austen's Emma (already in NLTK's text corpora). I bet we can do this with our split-up Blithedale text that we pulled in from Project Gutenberg...\n",
    "**NOTE**: You need to execute the previous cell for the next one to know the variables it needs.\n",
    "\n",
    "Basically, to make the concordance, you have to convert the list of tokens into a special NLTK **text object**, and then run the concordance feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1b4aa-ec10-455a-b94d-7955ea3014dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance = nltk.Text(splitEmUp).concordance(\"living\")\n",
    "print(f\"concordance = {concordance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898bdaea-db71-4319-b38e-e46af4672a01",
   "metadata": {},
   "source": [
    "### Frequency Distributions\n",
    "Here's an example plotting of frequency distributions. This is from the NLTK book, and you might be wondering why they didn't just use text4 for the corpus--which has all the addresses baked together in one file. They pulled from a **different** set, a collection of texts with each address stored in just one file, because the year of each address is in the fileid property! Being "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e55d8a-7a26-40b9-a1cb-d6e44d02e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import inaugural\n",
    "inaugural.fileids()\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (target,fileid[:4])\n",
    "    for fileid in inaugural.fileids()\n",
    "    # I added the next line to help make the plot more legible!\n",
    "    if int(fileid[:4]) > 1990\n",
    "    for w in inaugural.words(fileid)\n",
    "    for target in ['america', 'citizen']\n",
    "    if w.lower().startswith(target))\n",
    "cfd.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04066f7f-db56-4dc4-afbc-c02e9801cf3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f2569-4153-4022-9043-c50d7a971cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
